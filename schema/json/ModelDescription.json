{
  "$defs": {
    "BaseCompletionOptions": {
      "properties": {
        "temperature": {
          "anyOf": [
            {
              "type": "number"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "The temperature of the completion.",
          "title": "Temperature"
        },
        "top_p": {
          "anyOf": [
            {
              "type": "number"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "The top_p of the completion.",
          "title": "Top P"
        },
        "top_k": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "The top_k of the completion.",
          "title": "Top K"
        },
        "presence_penalty": {
          "anyOf": [
            {
              "type": "number"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "The presence penalty Aof the completion.",
          "title": "Presence Penalty"
        },
        "frequency_penalty": {
          "anyOf": [
            {
              "type": "number"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "The frequency penalty of the completion.",
          "title": "Frequency Penalty"
        },
        "stop": {
          "anyOf": [
            {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "The stop tokens of the completion.",
          "title": "Stop"
        },
        "max_tokens": {
          "default": 1023,
          "description": "The maximum number of tokens to generate.",
          "title": "Max Tokens",
          "type": "integer"
        },
        "session_id": {
          "title": "Session Id",
          "description": "The session_id of the UI.",
          "type": "string"
        }
      },
      "title": "BaseCompletionOptions",
      "type": "object"
    },
    "RequestOptions": {
      "properties": {
        "timeout": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": 300,
          "description": "Set the timeout for each request to the LLM. If you are running a local LLM that takes a while to respond, you might want to set this to avoid timeouts.",
          "title": "Timeout"
        },
        "verify_ssl": {
          "anyOf": [
            {
              "type": "boolean"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Whether to verify SSL certificates for requests.",
          "title": "Verify Ssl"
        },
        "ca_bundle_path": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Path to a custom CA bundle to use when making the HTTP request",
          "title": "Ca Bundle Path"
        },
        "proxy": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Proxy URL to use when making the HTTP request",
          "title": "Proxy"
        },
        "headers": {
          "anyOf": [
            {
              "additionalProperties": {
                "type": "string"
              },
              "type": "object"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Headers to use when making the HTTP request",
          "title": "Headers"
        }
      },
      "title": "RequestOptions",
      "type": "object"
    }
  },
  "additionalProperties": true,
  "properties": {
    "title": {
      "description": "The title you wish to give your model.",
      "title": "Title",
      "type": "string"
    },
    "provider": {
      "description": "The provider of the model. This is used to determine the type of model, and how to interact with it.",
      "enum": [
        "openai",
        "openai-free-trial",
        "openai-aiohttp",
        "anthropic",
        "together",
        "ollama",
        "huggingface-tgi",
        "huggingface-inference-api",
        "llama.cpp",
        "replicate",
        "text-gen-webui",
        "google-palm",
        "lmstudio",
        "llamafile"
      ],
      "title": "Provider",
      "type": "string"
    },
    "model": {
      "description": "The name of the model. Used to autodetect prompt template.",
      "title": "Model",
      "type": "string"
    },
    "api_key": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "OpenAI, Anthropic, Together, or other API key",
      "title": "Api Key"
    },
    "api_base": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The base URL of the LLM API.",
      "title": "Api Base"
    },
    "context_length": {
      "default": 2048,
      "description": "The maximum context length of the LLM in tokens, as counted by count_tokens.",
      "title": "Context Length",
      "type": "integer"
    },
    "template": {
      "anyOf": [
        {
          "enum": [
            "llama2",
            "alpaca",
            "zephyr",
            "phind",
            "anthropic",
            "chatml",
            "deepseek"
          ],
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "The chat template used to format messages. This is auto-detected for most models, but can be overridden here.",
      "title": "Template"
    },
    "completion_options": {
      "allOf": [
        {
          "$ref": "#/$defs/BaseCompletionOptions"
        }
      ],
      "default": {
        "temperature": null,
        "top_p": null,
        "top_k": null,
        "presence_penalty": null,
        "frequency_penalty": null,
        "stop": null,
        "max_tokens": 1023
      },
      "description": "Options for the completion endpoint. Read more about the completion options in the documentation."
    },
    "system_message": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "A system message that will always be followed by the LLM",
      "title": "System Message"
    },
    "request_options": {
      "allOf": [
        {
          "$ref": "#/$defs/RequestOptions"
        }
      ],
      "default": {
        "timeout": 300,
        "verify_ssl": null,
        "ca_bundle_path": null,
        "proxy": null,
        "headers": null
      },
      "description": "Options for the HTTP request to the LLM."
    }
  },
  "required": [
    "title",
    "provider",
    "model"
  ],
  "title": "ModelDescription",
  "type": "object"
}